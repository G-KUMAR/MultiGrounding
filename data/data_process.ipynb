{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/svebor/Grounding/MultiGrounding\n"
     ]
    }
   ],
   "source": [
    "# Make sure we're in the correct directory\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "if cwd.endswith('data'):\n",
    "    os.chdir('../')\n",
    "cwd = os.getcwd()\n",
    "print(cwd) # This should be the root of the repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Genome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and prepare Visual Genome \n",
    "\n",
    "If you do not have the VisualGenome dataset yet:\n",
    "1. download v1.2 images and region descriptions from [VisualGenome](https://visualgenome.org/api/v0/api_home.html)\n",
    "2. put all images under folder: `VG_Images`\n",
    "\n",
    "Otherwise, you can remove the directory `VG_Images` and create a symbolic link from your VisualGenome image directory (e.g. `/datasets/VisualGenome/`) to the `VG_Images` folder as follows:\n",
    "`ln -s /datasets/VisualGenome/ VG_Images`\n",
    "\n",
    "Then:\n",
    "1. put [region_descriptions.json](https://visualgenome.org/static/data/dataset/region_descriptions.json.zip) under folder: `VG_Annotations`\n",
    "2. make sure `imgs_data.pickle` (already included) is under `VG_Annotations`\n",
    "3. make sure `data_splits.pickle` (already included) is under `VG_Splits`\n",
    " \n",
    "NB: For fair comparison with SOTA\n",
    "1. we make sure train split doesn't have overlap with any test split of other datasets\n",
    "2. we take val set of coco as test split of vg and the rest of vg as train split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process Visual Genome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "from data.data_utils import Data\n",
    "data_saver = Data()\n",
    "data_saver(raw_path='./data/visual_genome/',save_path='./data/visual_genome_pp/',name='visual_genome',store_lmdb=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flickr30K Entities [TODO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and prepare Flickr30K Entities\n",
    "\n",
    "1. Clone the master branch from [https://github.com/BryanPlummer/flickr30k_entities](https://github.com/BryanPlummer/flickr30k_entities)\n",
    "2. Copy annotations.zip, in the `Flickr30k_Entities` folder and unzip it, this should generate and fill the subfolders `Sentences` and `Annotations`\n",
    "3. Put `train.txt`, `test.txt`, and `val.txt` in the `Flickr30k_Splits` folder\n",
    "4. Download flickr30k-images from [http://hockenmaier.cs.illinois.edu/DenotationGraph/](http://hockenmaier.cs.illinois.edu/DenotationGraph/) (Still waiting on a email to get download link...)\n",
    "5. Put all images in `Flickr30k_Images` folder\n",
    "6. Put folders `Flickr30k_Entities`, `Flickr30k_Images`, `Flickr30k_Splits` under `./data/flickr30k/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train split...\n",
      "0/29783 \r"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.1) /io/opencv/modules/imgcodecs/src/grfmt_base.cpp:145: error: (-10:Unknown error code -10) Raw image encoder error: Empty JPEG image (DNL not supported) in function 'throwOnEror'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c08cb22820fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_saver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata_saver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data/flickr30k/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data/flickr30k_pp/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'flickr30k_entities'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstore_lmdb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Grounding/MultiGrounding/data/data_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, raw_path, save_path, store_lmdb, name, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'flickr30k_entities'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flickr30k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstore_lmdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'coco'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstore_lmdb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'version'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Grounding/MultiGrounding/data/data_utils.py\u001b[0m in \u001b[0;36m_flickr30k\u001b[0;34m(self, raw_path, save_path, store_lmdb)\u001b[0m\n\u001b[1;32m    144\u001b[0m                                 \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                         \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                         \u001b[0mdict_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_dict_flickr30k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxml_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mannot_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msen_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimgs_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstore_lmdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m                         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannot_dict_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pickle'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Grounding/MultiGrounding/data/data_utils.py\u001b[0m in \u001b[0;36m_get_dict_flickr30k\u001b[0;34m(self, keys, xml_files, annot_path, sen_path, imgs_path, store_lmdb)\u001b[0m\n\u001b[1;32m    111\u001b[0m                                 \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                                 \u001b[0mimg_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                                 \u001b[0;32mwith\u001b[0m \u001b[0mstore_lmdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlmdb_txn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                                         \u001b[0mlmdb_txn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.1) /io/opencv/modules/imgcodecs/src/grfmt_base.cpp:145: error: (-10:Unknown error code -10) Raw image encoder error: Empty JPEG image (DNL not supported) in function 'throwOnEror'\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing\n",
    "from data.data_utils import Data\n",
    "data_saver = Data()\n",
    "data_saver(raw_path='./data/flickr30k/',save_path='./data/flickr30k_pp/',name='flickr30k_entities',store_lmdb=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReferIt  [TODO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and prepare ReferIt\n",
    "\n",
    "1. Download the `refclef` split from [http://bvisionweb1.cs.unc.edu/licheng/referit/data/refclef.zip](http://bvisionweb1.cs.unc.edu/licheng/referit/data/refclef.zip)\n",
    "2. Download the cleaned `refclef` images from [http://bvisionweb1.cs.unc.edu/licheng/referit/data/images/saiapr_tc-12.zip](http://bvisionweb1.cs.unc.edu/licheng/referit/data/images/saiapr_tc-12.zip)\n",
    "3. Unzip files of `refclef.zip` to `ReferIt_Splits`, not as a subfolder `refclef` in `ReferIt_Splits` but with the files directly in the folder `ReferIt_Splits`\n",
    "4. unzip files of `saiapr_tc-12.zip` to `ReferIt_Images`\n",
    "5. unzip files of `RefClef_Captions.tgz` (already included)\n",
    "Note: you can choose to download and process RefCOCO splits, but we used RefClef under \"UNC\" split (an established split in the area) and already included proper \"image_id\"s in the repo\n",
    "\n",
    "Questions? \n",
    "* Should the folder be `RefClef_Captions` or `ReferClef_Captions`\n",
    "* \n",
    "* No subfolder `saiapr_tc-12` in `ReferIt_Images`\n",
    "\n",
    "Error: No such file or directory: `./data/referit/ReferIt_Splits/referit_train_imlist.txt`\n",
    "\n",
    "Content of `ReferIt_Splits`:\n",
    "* `instances.json`, `refs(berkeley).p`, `refs(unc).p`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "from data.data_utils import Data\n",
    "data_saver = Data()\n",
    "data_saver(raw_path='./data/referit/',save_path='./data/referit_pp/',name='referit',store_lmdb=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MS-COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and prepare MS-COCO\n",
    "\n",
    "1. Clone and build python API of COCO dataset from [https://github.com/cocodataset/cocoapi/tree/master/PythonAPI](https://github.com/cocodataset/cocoapi/tree/master/PythonAPI) if not already installed\n",
    "2. Download coco train/val images and annotations ([train](http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
    ") and [test](http://images.cocodataset.org/annotations/image_info_test2014.zip\n",
    ")) from [http://cocodataset.org/#download](http://cocodataset.org/#download)\n",
    "3. Unzip all splits and put all images in one folder named: `COCO_Images`\n",
    "4. Unzip annotation files and put all files under them in `COCO_Annotations`\n",
    "\n",
    "\n",
    "Note: we used version 2014 in our evaluations\n",
    "\n",
    "Note: using 'gsutil' speeds up the process of downloading images (instructions available at [http://cocodataset.org/#download](http://cocodataset.org/#download))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train split...\n",
      "loading annotations into memory...\n",
      "Done (t=20.31s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.59s)\n",
      "creating index...\n",
      "index created!\n",
      "Using subfolder: train2014\n",
      "82783/82783 \n",
      "\n",
      "Processing val split...\n",
      "loading annotations into memory...\n",
      "Done (t=20.08s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=2.67s)\n",
      "creating index...\n",
      "index created!\n",
      "Using subfolder: val2014\n",
      "40504/40504 \n",
      "\n",
      "Processing done.\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing\n",
    "from data.data_utils import Data\n",
    "data_saver = Data()\n",
    "data_saver(raw_path='./data/coco/',save_path='./data/coco_pp/',name='coco',store_lmdb=True,version='2014')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
